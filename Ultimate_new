# image_processor.py
import os
import json
import uuid
from datetime import datetime
from typing import Optional

from dotenv import load_dotenv
load_dotenv()

from azure.core.credentials import AzureKeyCredential
from azure.ai.documentintelligence.aio import DocumentIntelligenceClient
from azure.storage.blob.aio import BlobServiceClient
from azure.core.exceptions import ResourceNotFoundError

from service import _require_env, get_env_values, AZURE_STORAGE_CONNECTION_STRING, _parse_blob_url

# Temporary output JSON filename (keeps same behaviour)
LOCAL_OUTPUT_FILENAME = "output.json"


async def analyze_file_async(bloburl: str) -> dict:
    """
    Download the PDF from bloburl (saved locally using the blob's basename),
    analyze it using Azure Document Intelligence, save output.json locally,
    upload JSON to 'output-results' container and return result dict.
    """
    # Validate env
    try:
        _require_env()
    except Exception as e:
        return {"status": False, "error": str(e)}

    endpoint, key, model_id = get_env_values()

    # Parse blob url -> (container, blob_path)
    try:
        src_container, src_blob = _parse_blob_url(bloburl)
    except Exception as e:
        return {"status": False, "error": f"Invalid BlobUrl: {e}"}

    # Extract the basename of the blob (the PDF filename)
    source_file_name = os.path.basename(src_blob) if src_blob else "unknown.pdf"
    # sanitize filename to avoid weird paths (this keeps basename only)
    source_file_name = os.path.basename(source_file_name)

    # Download PDF bytes from blob storage
    if not AZURE_STORAGE_CONNECTION_STRING:
        return {"status": False, "error": "Missing AZURE_STORAGE_CONNECTION_STRING in .env"}

    try:
        async with BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING) as blob_service:
            container_client = blob_service.get_container_client(src_container)
            blob_client = container_client.get_blob_client(src_blob)
            try:
                await blob_client.get_blob_properties()
            except ResourceNotFoundError:
                return {"status": False, "error": f"PDF blob not found: container='{src_container}', blob='{src_blob}'"}

            stream = await blob_client.download_blob()
            pdf_bytes = await stream.readall()
    except Exception as e:
        return {"status": False, "error": f"Error downloading PDF from Blob Storage: {e}"}

    # Write to local file using the original filename
    input_path = os.path.join(os.getcwd(), source_file_name)
    try:
        with open(input_path, "wb") as wf:
            wf.write(pdf_bytes)
    except Exception as e:
        return {"status": False, "error": f"Failed to write local input file '{input_path}': {e}"}

    # Analyze using Azure Document Intelligence (async)
    try:
        client = DocumentIntelligenceClient(endpoint=endpoint, credential=AzureKeyCredential(key))
    except Exception as e:
        return {"status": False, "error": f"Failed to create DocumentIntelligenceClient: {e}"}

    try:
        async with client:
            with open(input_path, "rb") as f:
                poller = await client.begin_analyze_document(model_id=model_id, body=f)
                result = await poller.result()
    except Exception as e:
        return {"status": False, "error": f"Error during document analysis: {e}"}

    # Save JSON locally as output.json (temporary)
    output_path = os.path.join(os.getcwd(), LOCAL_OUTPUT_FILENAME)
    json_data = result.as_dict()
    try:
        with open(output_path, "w", encoding="utf-8") as wf:
            json.dump(json_data, wf, indent=2, ensure_ascii=False)
    except Exception as e:
        return {"status": False, "error": f"Failed to save local output.json: {e}"}

    # Upload JSON to output-results container
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    unique = uuid.uuid4().hex
    target_blob_name = f"{timestamp}_{unique}_extracted_{timestamp}.json"
    output_container = "output-results"

    try:
        async with BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING) as blob_service:
            out_container_client = blob_service.get_container_client(output_container)
            # Try to create container if missing (best-effort)
            try:
                await out_container_client.create_container()
            except Exception:
                pass

            out_blob_client = out_container_client.get_blob_client(target_blob_name)
            json_bytes = json.dumps(json_data, indent=2, ensure_ascii=False).encode("utf-8")
            await out_blob_client.upload_blob(json_bytes, overwrite=True)
    except Exception as e:
        return {"status": False, "error": f"Failed to upload JSON to output-results: {e}"}

    # Build full output blob URL using the same account domain as the incoming bloburl
    parsed = bloburl.split("://", 1)[-1]  # e.g. account.blob.core.windows.net/...
    account_and_rest = parsed.split("/", 1)[0]  # account.blob.core.windows.net
    output_blob_url = f"https://{account_and_rest}/{output_container}/{target_blob_name}"

    return {
        "status": True,
        "source_file": source_file_name,
        "output_blob_url": output_blob_url
    }


async def process_input_folder_on_startup() -> None:
    """
    Lightweight startup task invoked by main.lifespan:
      - checks ./input for any PDFs and prints them
      - does NOT auto-upload or auto-analyze local files (you can extend as needed)
    This keeps it safe and non-blocking on startup.
    """
    try:
        input_dir = os.path.join(os.getcwd(), "input")
        if not os.path.exists(input_dir):
            # nothing to do
            return

        files = [f for f in os.listdir(input_dir) if f.lower().endswith(".pdf")]
        if not files:
            return

        for pdf in files:
            print(f"[startup] Found local PDF in ./input: {pdf} â€” no automatic processing. To analyze, call the MCP endpoint with the blob URL.")
    except Exception as e:
        # swallow any startup errors so app can start
        print(f"[startup] process_input_folder_on_startup error: {e}")
        return
