Here are the updated files (clean code only, as requested):

â¸»

main.py

# main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi_mcp import FastApiMCP
import uvicorn
from contextlib import asynccontextmanager

from routers.attachment_router import router as attachment_router
from attachment_service import start_email_polling, stop_email_polling

def apply_cors(app: FastAPI):
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
    )

@asynccontextmanager
async def lifespan(app: FastAPI):
    await start_email_polling()
    yield
    await stop_email_polling()

def create_sub_app(title: str, description: str, version: str = "0.1.0") -> FastAPI:
    sub = FastAPI(title=title, description=description, version=version, lifespan=lifespan)
    apply_cors(sub)
    return sub

app = FastAPI(lifespan=lifespan)
apply_cors(app)

email_app = create_sub_app(
    title="attachment_checker_mcp",
    description="Reads latest emails and compares attachment filenames with Azure Blob names."
)
email_app.include_router(attachment_router)

FastApiMCP(email_app, include_operations=["attachment_checker_mcp"]).mount_http()
app.mount("/mcp", email_app)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8502)


â¸»

attachment_handler.py

import os
import json
import base64
from azure.storage.blob import BlobServiceClient
from dotenv import load_dotenv

load_dotenv()

STATE_FILE = os.path.join("storage", "history_state.json")
OUTPUT_DIR = os.path.join("storage", "attachments")
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(os.path.dirname(STATE_FILE), exist_ok=True)

AZURE_STORAGE_CONNECTION_STRING = os.environ.get("AZURE_STORAGE_CONNECTION_STRING", "")
AZURE_BLOB_CONTAINER = os.environ.get("AZURE_BLOB_CONTAINER", "")

def _get_blob_service_client():
    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("Missing AZURE_STORAGE_CONNECTION_STRING")
    return BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)

def _ensure_container_exists(blob_service_client):
    if not AZURE_BLOB_CONTAINER:
        raise RuntimeError("Missing AZURE_BLOB_CONTAINER")
    container_client = blob_service_client.get_container_client(AZURE_BLOB_CONTAINER)
    try:
        container_client.create_container()
    except Exception:
        pass
    return container_client

def load_state():
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, indent=2, ensure_ascii=False)

def _walk_parts(parts):
    for p in parts or []:
        yield p
        for sub in p.get("parts", []) or []:
            yield from _walk_parts([sub])

def save_attachments_from_message(service, message):
    """
    Extract attachment filenames from Gmail message and compare with Azure Blob Storage.
    Success: returns {"attachments": [{"filename": "...", "is_duplicate": bool}, ...]}
    No attachments: returns {"attachments": []}
    Azure/Gmail errors: raise exception â†’ caller returns status:false + error
    """
    filenames = []
    parts = message.get("payload", {}).get("parts", [])
    for part in _walk_parts(parts):
        filename = part.get("filename")
        _ = part.get("body", {}) or {}
        if filename:
            filenames.append(filename)

    if not filenames:
        try:
            out_path = os.path.join(OUTPUT_DIR, f"{message.get('id', 'unknown')}_comparison.json")
            with open(out_path, "w", encoding="utf-8") as f:
                json.dump({"attachments": []}, f, indent=2, ensure_ascii=False)
        except Exception as exc:
            print(f"Failed to write comparison result file: {exc}")
        return {"attachments": []}

    blob_service_client = _get_blob_service_client()
    container_client = _ensure_container_exists(blob_service_client)

    attachment_results = []
    for name in filenames:
        blob_client = container_client.get_blob_client(blob=name)
        is_duplicate = bool(blob_client.exists())
        attachment_results.append({
            "filename": name,
            "is_duplicate": is_duplicate
        })

    try:
        out_path = os.path.join(OUTPUT_DIR, f"{message.get('id', 'unknown')}_comparison.json")
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump({"attachments": attachment_results}, f, indent=2, ensure_ascii=False)
    except Exception as exc:
        print(f"Failed to write comparison result file: {exc}")

    return {"attachments": attachment_results}


â¸»

attachment_service.py

import asyncio
import json
from datetime import datetime
from typing import Dict, Any
from gmail_watch import get_gmail_service
from attachment_handler import save_attachments_from_message

_last_check_time = None
_is_polling = True

def _extract_attachment_comparison(service, msg) -> Dict[str, Any]:
    comparison = save_attachments_from_message(service, msg)
    return {
        "message_id": msg.get("id", ""),
        "attachments": comparison.get("attachments", [])
    }

def get_latest_email_attachment_check() -> Dict[str, Any]:
    """
    Success (even if no emails or no attachments):
      {"status": True, "attachments": [...]}
    Failure (on any exception):
      {"status": False, "error": "..."}
    """
    try:
        service = get_gmail_service()
        results = service.users().messages().list(userId="me", maxResults=1).execute()
        messages = results.get("messages", [])

        if not messages:
            return {"status": True, "attachments": []}

        msg = service.users().messages().get(
            userId="me",
            id=messages[0]["id"],
            format="full"
        ).execute()

        comparison = _extract_attachment_comparison(service, msg)
        return {"status": True, "attachments": comparison.get("attachments", [])}

    except Exception as e:
        return {"status": False, "error": str(e)}

async def _check_for_new_emails():
    """
    During polling: print full JSON ONLY for messages found in this cycle (i.e., since last_check_time).
    On per-message errors: print full JSON with status:false + error.
    """
    global _last_check_time
    try:
        service = get_gmail_service()

        if not _last_check_time:
            results = service.users().messages().list(userId="me", maxResults=5).execute()
        else:
            query = f"after:{int(_last_check_time.timestamp())}"
            results = service.users().messages().list(userId="me", q=query).execute()

        messages = results.get("messages", [])
        for message in messages:
            try:
                msg = service.users().messages().get(
                    userId="me",
                    id=message["id"],
                    format="full"
                ).execute()
                comparison = _extract_attachment_comparison(service, msg)
                result = {
                    "status": True,
                    "attachments": comparison.get("attachments", [])
                }
                print(json.dumps(result, indent=2))
            except Exception as inner_e:
                error_result = {"status": False, "error": str(inner_e)}
                print(json.dumps(error_result, indent=2))

        _last_check_time = datetime.now()

    except Exception as e:
        print(f"Error checking for new emails: {e}")

async def _email_polling_loop():
    global _is_polling
    print("ðŸ“§ Email polling loop started.")
    while _is_polling:
        await _check_for_new_emails()
        await asyncio.sleep(10)
    print("ðŸ“ª Email polling loop stopped.")

async def start_email_polling():
    global _is_polling, _last_check_time
    _is_polling = True

    bootstrap = get_latest_email_attachment_check()
    print("âœ… Latest Attachment Comparison:")
    print(json.dumps(bootstrap, indent=2))

    asyncio.create_task(_email_polling_loop())

async def stop_email_polling():
    global _is_polling
    _is_polling = False
    print("ðŸ›‘ Shutting down email monitoring...")


â¸»

routers/attachment_router.py

from fastapi import APIRouter
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

from attachment_service import get_latest_email_attachment_check

router = APIRouter()

class AttachmentCheckerMCP(BaseModel):
    AgentName: str = Field(default="EmailAttachmentChecker", description="Agent name.")
    UserId: str = Field(default="markRuffalo", description="User id (default).")

@router.post("/attachment_checker_mcp", operation_id="attachment_checker_mcp")
async def attachment_checker_mcp(p_body: AttachmentCheckerMCP):
    try:
        result = get_latest_email_attachment_check()
        if result.get("status") is True and "attachments" not in result:
            result["attachments"] = []
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": result
            }
        )
    except Exception as e:
        return JSONResponse(
            content={
                "jsonrpc": "2.0",
                "id": 1,
                "result": {"status": False, "error": str(e)}
            },
            status_code=200
        )


â¸»

gmail_watch.py (unchanged)

import os
import pickle
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build

SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']

def get_gmail_service(force_auth=False):
    creds = None
    token_path = "token.pickle"
    credentials_dir = "credentials"
    client_secret_path = os.path.join(credentials_dir, "client_secret.json")

    if not os.path.exists(credentials_dir):
        os.makedirs(credentials_dir, exist_ok=True)
        print(f" Created credentials directory at {credentials_dir}")

    if not os.path.exists(client_secret_path):
        raise FileNotFoundError(
            f" {client_secret_path} not found. Place your Google OAuth credentials file here."
        )

    if not force_auth and os.path.exists(token_path):
        try:
            with open(token_path, "rb") as f:
                creds = pickle.load(f)
            if creds and creds.valid:
                print(" Loaded existing valid credentials")
                return build("gmail", "v1", credentials=creds, cache_discovery=False)
        except Exception as e:
            print(f" Error loading existing token: {e}")
            creds = None

    try:
        if os.path.exists(token_path):
            os.remove(token_path)
            print(" Removed existing token to force new authentication")

        print(" Starting Gmail OAuth authentication flow...")
        flow = InstalledAppFlow.from_client_secrets_file(client_secret_path, SCOPES)
        creds = flow.run_local_server(port=0, prompt='consent', success_message="Gmail authentication successful! You can close this window.", open_browser=True)

        with open(token_path, "wb") as f:
            pickle.dump(creds, f)
        print(" Authentication successful - credentials saved")
    except Exception as e:
        print(f"Authentication error: {e}")
        raise

    return build("gmail", "v1", credentials=creds, cache_discovery=False)

def create_watch(project_id, topic_full_name):
    service = get_gmail_service()
    body = {"labelIds": ["INBOX"], "topicName": topic_full_name}
    resp = service.users().watch(userId="me", body=body).execute()
    print("Watch created:", resp)
    return resp

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 3:
        print("Usage: python gmail_watch.py <PROJECT_ID> <projects/PROJECT_ID/topics/TOPIC>")
        sys.exit(1)
    project = sys.argv[1]
    topic = sys.argv[2]
    create_watch(project, topic)


â¸»
