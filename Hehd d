Perfect ‚úÖ
Let‚Äôs restate your requirements clearly before I write the final version of your complete working code (with all files you need):

‚∏ª

üéØ Updated Requirements

We want a service that:
	1.	Takes a blob URL (PDF) input from Azure.
	2.	Downloads that PDF file into the input/ folder (which is in your root directory).
	3.	Converts only the first page of the PDF into an image.
	4.	Sends that image to Azure OpenAI GPT-4o (vision model) using your existing chat deployment (AZURE_OPENAI_CHAT_DEPLOYMENT = "gpt4o").
	5.	Uses a prompt that tells GPT-4o:
‚ÄúClassify whether the uploaded PDF document is structured (templated, forms, tables, invoices, quotes) or unstructured (free text, letters, paragraphs). Respond with only the word ‚Äòstructured‚Äô or ‚Äòunstructured‚Äô.‚Äù
	6.	GPT-4o returns the classification ("structured" or "unstructured").
	7.	The API response should only contain:

{
  "result": "structured"
}

or

{
  "result": "unstructured"
}


	8.	No OCR, no heuristics, no custom extraction model ‚Äî only GPT-4o classification.

‚∏ª

‚úÖ Architecture Summary

Your project structure will look like this:

layout_detection/
‚îÇ
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ file_router.py
‚îú‚îÄ‚îÄ handler.py
‚îú‚îÄ‚îÄ service.py
‚îú‚îÄ‚îÄ llm_client.py
‚îú‚îÄ‚îÄ pdf_utils.py
‚îú‚îÄ‚îÄ test_scripts.py
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ input/


‚∏ª

üß† .env File Example

AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=...your_connection_string...
AZURE_OPENAI_API_KEY=your_azure_openai_key
AZURE_OPENAI_ENDPOINT=https://yourresource.openai.azure.com
AZURE_OPENAI_API_VERSION=2024-08-01-preview
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt4o


‚∏ª

üß© Complete Code

‚∏ª

service.py

import os
from urllib.parse import urlparse, unquote
from dotenv import load_dotenv

load_dotenv()

AZURE_STORAGE_CONNECTION_STRING = os.getenv("AZURE_STORAGE_CONNECTION_STRING", "")
INPUT_ROOT = "input"


def _require_env() -> None:
    """Ensure required environment variables exist."""
    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("Missing AZURE_STORAGE_CONNECTION_STRING in .env")


def _parse_blob_url(url: str) -> tuple[str, str]:
    """Parse an Azure Blob URL into (container, blob_path)."""
    parsed = urlparse(url)
    path = parsed.path.lstrip("/")
    parts = path.split("/", 1)
    if len(parts) != 2:
        raise ValueError("Invalid blob URL format.")
    return unquote(parts[0]), unquote(parts[1])


def ensure_input_folder():
    """Ensure 'input' folder exists."""
    os.makedirs(INPUT_ROOT, exist_ok=True)
    return INPUT_ROOT


‚∏ª

pdf_utils.py

import os
from azure.storage.blob.aio import BlobServiceClient
from azure.core.exceptions import ResourceNotFoundError
import fitz  # PyMuPDF
from service import AZURE_STORAGE_CONNECTION_STRING, ensure_input_folder, _parse_blob_url


async def download_pdf_from_blob(blob_url: str) -> str:
    """Download PDF from Azure Blob and store it in input folder."""
    ensure_input_folder()
    container, blob_path = _parse_blob_url(blob_url)

    async with BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING) as blob_service:
        blob_client = blob_service.get_blob_client(container=container, blob=blob_path)
        try:
            await blob_client.get_blob_properties()
        except ResourceNotFoundError:
            raise FileNotFoundError(f"Blob not found: {blob_path}")

        stream = await blob_client.download_blob()
        data = await stream.readall()

    local_path = os.path.join("input", os.path.basename(blob_path))
    with open(local_path, "wb") as f:
        f.write(data)

    return local_path


def convert_pdf_first_page_to_image(pdf_path: str) -> str:
    """Convert first page of a PDF to PNG image."""
    doc = fitz.open(pdf_path)
    if doc.page_count < 1:
        raise ValueError("Empty PDF file.")

    page = doc.load_page(0)
    pix = page.get_pixmap(dpi=150)
    image_path = os.path.splitext(pdf_path)[0] + "_page1.png"
    pix.save(image_path)
    doc.close()

    return image_path


‚∏ª

llm_client.py

import os
import base64
import requests
from dotenv import load_dotenv

load_dotenv()

AZURE_KEY = os.getenv("AZURE_OPENAI_API_KEY")
AZURE_ENDPOINT = os.getenv("AZURE_OPENAI_ENDPOINT")
AZURE_VERSION = os.getenv("AZURE_OPENAI_API_VERSION")
DEPLOYMENT = os.getenv("AZURE_OPENAI_CHAT_DEPLOYMENT")


def analyze_layout_with_gpt4o(image_path: str) -> str:
    """Send first-page image to GPT-4o to classify structured/unstructured."""

    if not (AZURE_KEY and AZURE_ENDPOINT and AZURE_VERSION and DEPLOYMENT):
        raise RuntimeError("Missing Azure OpenAI environment variables.")

    # Read image bytes and encode to base64
    with open(image_path, "rb") as f:
        img_base64 = base64.b64encode(f.read()).decode("utf-8")

    # Prompt for classification
    prompt = (
        "You are a document layout classifier. "
        "Based on the visual layout of the provided image (first page of a PDF), "
        "classify whether the document is structured (templated forms, invoices, tables, quotes) "
        "or unstructured (letters, paragraphs, free text). "
        "Respond with only one word: 'structured' or 'unstructured'."
    )

    url = f"{AZURE_ENDPOINT}/openai/deployments/{DEPLOYMENT}/chat/completions?api-version={AZURE_VERSION}"

    headers = {
        "Content-Type": "application/json",
        "api-key": AZURE_KEY
    }

    payload = {
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": f"data:image/png;base64,{img_base64}"}
                ]
            }
        ],
        "max_tokens": 20,
        "temperature": 0.0
    }

    response = requests.post(url, headers=headers, json=payload, timeout=120)
    response.raise_for_status()
    data = response.json()
    result = data["choices"][0]["message"]["content"].strip().lower()

    if "structured" in result:
        return "structured"
    elif "unstructured" in result:
        return "unstructured"
    else:
        return "unstructured"  # fallback


‚∏ª

handler.py

import json
from typing import Dict
from pdf_utils import download_pdf_from_blob, convert_pdf_first_page_to_image
from llm_client import analyze_layout_with_gpt4o
from service import _require_env

async def process_pdf_layout(blob_url: str) -> Dict:
    """
    Flow:
    1. Download PDF from blob
    2. Convert first page to image
    3. Send to GPT-4o for classification
    4. Return {'result': 'structured'} or {'result': 'unstructured'}
    """
    try:
        _require_env()
        pdf_path = await download_pdf_from_blob(blob_url)
        image_path = convert_pdf_first_page_to_image(pdf_path)
        layout_type = analyze_layout_with_gpt4o(image_path)
        return {"result": layout_type}

    except Exception as e:
        return {"error": str(e)}


‚∏ª

file_router.py

from fastapi import APIRouter
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
from handler import process_pdf_layout

router = APIRouter()

class PDFLayoutRequest(BaseModel):
    blob_url: str = Field(..., description="Azure Blob URL of the PDF file")

@router.post(
    "/layout_detection_mcp",
    operation_id="layout_detection_mcp",
    summary="Detect document layout as structured or unstructured using GPT-4o."
)
async def detect_layout(request: PDFLayoutRequest):
    try:
        result = await process_pdf_layout(request.blob_url)
        return JSONResponse(content=result, status_code=200)
    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)


‚∏ª

main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi_mcp import FastApiMCP
import uvicorn
from file_router import router as file_router

def apply_cors(app: FastAPI):
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_methods=["*"],
        allow_headers=["*"],
    )

app = FastAPI(title="Layout Detection MCP", description="Detect structured/unstructured documents using GPT-4o.")
apply_cors(app)

file_app = FastAPI(title="Layout Detection SubApp")
file_app.include_router(file_router)

FastApiMCP(file_app, include_operations=["layout_detection_mcp"]).mount_http()

app.mount("/api/v1/layout_agent", file_app)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8601)


‚∏ª

test_scripts.py

import requests
import json

BASE_URL = "http://localhost:8601/api/v1/layout_agent/layout_detection_mcp"

def run_test():
    payload = {
        "blob_url": "https://youraccount.blob.core.windows.net/yourcontainer/sample.pdf"
    }

    response = requests.post(BASE_URL, json=payload)
    print("Status:", response.status_code)
    print(json.dumps(response.json(), indent=4))

if __name__ == "__main__":
    run_test()


‚∏ª

‚úÖ Output Example

If structured:

{
  "result": "structured"
}

If unstructured:

{
  "result": "unstructured"
}


‚∏ª

Would you like me to modify the prompt slightly to make GPT-4o more strict in replying only the exact word (structured/unstructured, nothing else)?
I can add a one-line rule like:

‚ÄúReply with only one lowercase word: structured or unstructured. Do not include punctuation or explanations.‚Äù
