# llm_client.py  (legacy-simple)
import os
import base64
import openai
from dotenv import load_dotenv
from typing import Dict, Any

load_dotenv()

AZURE_OPENAI_API_KEY = os.environ.get("AZURE_OPENAI_API_KEY")
AZURE_OPENAI_ENDPOINT = os.environ.get("AZURE_OPENAI_ENDPOINT")
AZURE_OPENAI_API_VERSION = os.environ.get("AZURE_OPENAI_API_VERSION")
AZURE_OPENAI_CHAT_DEPLOYMENT = os.environ.get("AZURE_OPENAI_CHAT_DEPLOYMENT") or os.environ.get("AZURE_OPENAI_CHAT_DEPLOYMENT_NAME")

def _require_env():
    missing = []
    if not AZURE_OPENAI_API_KEY: missing.append("AZURE_OPENAI_API_KEY")
    if not AZURE_OPENAI_ENDPOINT: missing.append("AZURE_OPENAI_ENDPOINT")
    if not AZURE_OPENAI_API_VERSION: missing.append("AZURE_OPENAI_API_VERSION")
    if not AZURE_OPENAI_CHAT_DEPLOYMENT: missing.append("AZURE_OPENAI_CHAT_DEPLOYMENT")
    if missing:
        raise RuntimeError("Missing env vars: " + ", ".join(missing))

# configure azure-style for legacy client
def _build_legacy_client():
    _require_env()
    openai.api_type = "azure"
    openai.api_key = AZURE_OPENAI_API_KEY
    openai.api_base = AZURE_OPENAI_ENDPOINT.rstrip("/")
    openai.api_version = AZURE_OPENAI_API_VERSION
    return openai

def _data_uri_from_bytes(image_bytes: bytes, mime: str = "image/png") -> str:
    return f"data:{mime};base64," + base64.b64encode(image_bytes).decode("utf-8")

def classify_layout_from_image_bytes(image_bytes: bytes, extra_context: str = "") -> Dict[str, Any]:
    """
    Simple: embed small image as data URI (image_bytes should be downscaled) into a short prompt.
    Uses legacy openai.ChatCompletion.create(...) with engine=<deployment>.
    Returns: {"raw": "<raw text>", "layout_type": "structured"|"unstructured"}
    """
    client = _build_legacy_client()
    data_uri = _data_uri_from_bytes(image_bytes)

    system_text = (
        "You are a document layout classifier. You will get an image. Respond with EXACTLY one lowercase word only: "
        "'structured' or 'unstructured'. If unsure, reply 'unstructured'. No extra text."
    )

    user_text = extra_context + "\n\nImage (data URI):\n" + data_uri + "\n\nReturn exactly one word: structured OR unstructured."

    try:
        resp = client.ChatCompletion.create(
            engine=AZURE_OPENAI_CHAT_DEPLOYMENT,
            messages=[
                {"role": "system", "content": system_text},
                {"role": "user", "content": user_text}
            ],
            max_tokens=4,
            temperature=0.0,
        )
    except Exception as e:
        raise RuntimeError(f"LLM request failed: {e}")

    # extract text
    try:
        llm_text = resp.choices[0].message["content"]
    except Exception:
        llm_text = getattr(resp.choices[0], "text", "")

    text_clean = (llm_text or "").strip().lower()
    if text_clean == "structured":
        layout = "structured"
    elif text_clean == "unstructured":
        layout = "unstructured"
    else:
        layout = "unstructured"  # safe default

    return {"raw": llm_text, "layout_type": layout}
