import os
import json
import base64
import re
from azure.storage.blob import BlobServiceClient
from dotenv import load_dotenv

load_dotenv()

STATE_FILE = os.path.join("storage", "history_state.json")
OUTPUT_DIR = os.path.join("storage", "attachments")
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(os.path.dirname(STATE_FILE), exist_ok=True)

AZURE_STORAGE_CONNECTION_STRING = os.environ.get("AZURE_STORAGE_CONNECTION_STRING", "")
AZURE_BLOB_CONTAINER = os.environ.get("AZURE_BLOB_CONTAINER", "")

def _get_blob_service_client():
    if not AZURE_STORAGE_CONNECTION_STRING:
        raise RuntimeError("Missing AZURE_STORAGE_CONNECTION_STRING")
    return BlobServiceClient.from_connection_string(AZURE_STORAGE_CONNECTION_STRING)

def _ensure_container_exists(blob_service_client):
    if not AZURE_BLOB_CONTAINER:
        raise RuntimeError("Missing AZURE_BLOB_CONTAINER")
    container_client = blob_service_client.get_container_client(AZURE_BLOB_CONTAINER)
    try:
        container_client.create_container()
    except Exception:
        pass
    return container_client

def load_state():
    try:
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f, indent=2, ensure_ascii=False)

def _walk_parts(parts):
    for p in parts or []:
        yield p
        for sub in p.get("parts", []) or []:
            yield from _walk_parts([sub])

def _blob_exists_for_attachment(container_client, attachment_name):
    """
    Returns True if any blob corresponds to the given attachment_name using the new naming rule:
      - New format: <referenceid>_attachment_<filename>
    We no longer check for exact blob name == attachment_name.
    """
    search_token = f"_attachment_{attachment_name}"
    try:
        # list_blobs may be expensive for very large containers; this directly scans blob names.
        for blob in container_client.list_blobs():
            # match if the search token appears in the blob name (handles folder prefixes)
            if search_token in blob.name:
                return True
    except Exception as e:
        print(f"Error while listing blobs for pattern search '{search_token}': {e}")

    return False

def save_attachments_from_message(service, message):
    """
    Extract attachment filenames from Gmail message and compare with Azure Blob Storage.
    Always returns {"attachments": [ { "filename": ..., "is_duplicate": True/False/"NA" }, ... ]}
    If no attachments: returns {"attachments": []}
    """
    filenames = []
    parts = message.get("payload", {}).get("parts", [])
    for part in _walk_parts(parts):
        filename = part.get("filename")
        _ = part.get("body", {}) or {}
        if filename:
            filenames.append(filename)

    if not filenames:
        try:
            out_path = os.path.join(OUTPUT_DIR, f"{message.get('id', 'unknown')}_comparison.json")
            with open(out_path, "w", encoding="utf-8") as f:
                json.dump({"attachments": []}, f, indent=2, ensure_ascii=False)
        except Exception as exc:
            print(f"Failed to write comparison result file: {exc}")
        return {"attachments": []}

    # Pattern to decide which files should be checked against blob storage.
    # Files that do NOT match this pattern will be returned with "is_duplicate": "NA".
    accord_pattern = re.compile(r"acord|quote", re.IGNORECASE)

    blob_service_client = None
    container_client = None
    # Delay creating blob client until we actually need it (i.e., at least one file matches).
    if any(accord_pattern.search(fn) for fn in filenames):
        try:
            blob_service_client = _get_blob_service_client()
            container_client = _ensure_container_exists(blob_service_client)
        except Exception as e:
            # If we cannot create the container client, log and proceed: matched files will be marked is_duplicate=False
            print(f"Warning: unable to initialize Azure Blob client: {e}")
            container_client = None

    attachment_results = []
    for name in filenames:
        if accord_pattern.search(name):
            # This filename should be checked against blob storage.
            try:
                if container_client:
                    is_duplicate = _blob_exists_for_attachment(container_client, name)
                else:
                    # If container client couldn't be created, treat as not duplicate but log the situation.
                    print(f"Container client not available; treating '{name}' as not duplicate.")
                    is_duplicate = False
            except Exception as e:
                print(f"Error checking blob existence for '{name}': {e}")
                is_duplicate = False
        else:
            # Not a file we want to check â€” return string "NA" as requested.
            is_duplicate = "NA"

        attachment_results.append({
            "filename": name,
            "is_duplicate": is_duplicate
        })

    # Write comparison result file (best-effort)
    try:
        out_path = os.path.join(OUTPUT_DIR, f"{message.get('id', 'unknown')}_comparison.json")
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump({"attachments": attachment_results}, f, indent=2, ensure_ascii=False)
    except Exception as exc:
        print(f"Failed to write comparison result file: {exc}")

    return {"attachments": attachment_results}
